{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import gc\n",
    "import psutil\n",
    "from dictionary_corpus import Corpus, TextDataset, Vocabulary, word_tokenizer, collate_batch, tokenize\n",
    "import model\n",
    "from lm_argparser import lm_parser\n",
    "from utils import (\n",
    "    repackage_hidden,\n",
    "    get_batch,\n",
    "    batchify,\n",
    "    save_checkpoint,\n",
    "    move_to_device,\n",
    "    save_val_loss_data,\n",
    "    load_model,\n",
    "    get_memory_usage,\n",
    "    log_memory_usage,\n",
    "    clear_memory\n",
    ")\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import multiprocessing as mp\n",
    "from simple_data import TokenDataset, get_batch_iterators\n",
    "from torch.nn.functional import scaled_dot_product_attention\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus('/scratch2/mrenaudin/colorlessgreenRNNs/english_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_batch_size = 10\n",
    "\n",
    "val_data = batchify(corpus.valid, eval_batch_size, device)\n",
    "test_data = batchify(corpus.test, eval_batch_size, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.train = tokenize(corpus.dictionary, os.path.join('/scratch2/mrenaudin/colorlessgreenRNNs/english_data', 'train.txt'), shuffle=True)\n",
    "train_data = batchify(corpus.train, 128, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBR_RNN(nn.Module):\n",
    "    # goal here is to reuse CBR_RNN but with scaled dot product attention for more efficient computations.\n",
    "    # Also I got rid of options such as loading pretrained embeddings, and ablating attention to simplify the code.\n",
    "    # In the future if those options are needed, they can still be copy pasted from William's code as the structure hasn't changed\n",
    "    def __init__(self, ntoken, ninp, nhid, nheads, dropout=0.5, device=None):\n",
    "        super().__init__()\n",
    "        # same layers as Timkey\n",
    "        self.device = device\n",
    "        self.nheads = nheads\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.score_attn = nn.Softmax(dim=-1)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        self.q = nn.Linear(ninp + nhid, nhid)\n",
    "        self.intermediate_h = nn.Linear(nhid * 4, nhid * 4)\n",
    "        self.decoder = nn.Linear(nhid, ntoken)\n",
    "        self.q_norm = torch.nn.LayerNorm(nhid)\n",
    "        self.int_norm = torch.nn.LayerNorm(nhid * 4)\n",
    "        self.f_norm = torch.nn.LayerNorm(nhid * 3)\n",
    "        self.nhid = nhid\n",
    "        self.final_h = nn.Linear(nhid * 4, nhid * 3)\n",
    "        self.multihead_attn = nn.MultiheadAttention(\n",
    "            embed_dim=nhid, num_heads=nheads, batch_first=True\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"Initialize model weights for better training dynamics\"\"\"\n",
    "        # General initialization\n",
    "        for name, param in self.named_parameters():\n",
    "            if \"weight\" in name:\n",
    "                if \"norm\" in name:\n",
    "                    nn.init.ones_(param)\n",
    "                elif \"encoder\" in name:\n",
    "                    nn.init.normal_(param, mean=0, std=0.01)\n",
    "                elif \"decoder\" in name:\n",
    "                    nn.init.normal_(param, mean=0, std=0.01)\n",
    "                else:\n",
    "                    # Standard He initialization for processing layers\n",
    "                    nn.init.kaiming_normal_(param, mode=\"fan_in\", nonlinearity=\"tanh\")\n",
    "            elif \"bias\" in name:\n",
    "                nn.init.zeros_(param)\n",
    "\n",
    "    def init_cache(self, observation, nheads):\n",
    "        \"\"\"Initialize hidden state and attention caches with better initialization strategy\"\"\"\n",
    "        if len(observation.size()) > 1:\n",
    "            bsz = observation.size(dim=-1)\n",
    "        else:\n",
    "            bsz = 1\n",
    "\n",
    "        hidden = torch.zeros(1, bsz, self.nhid).to(self.device) \n",
    "        if nheads == 1:\n",
    "            key_cache = torch.zeros(bsz, 1, 1, self.nhid).to(self.device) \n",
    "            value_cache = torch.zeros(bsz, 1, 1, self.nhid).to(self.device) \n",
    "        else:\n",
    "            key_cache = torch.zeros(bsz, 1, self.nhid).to(self.device) \n",
    "            value_cache = torch.zeros(bsz, 1, self.nhid).to(self.device) \n",
    "        return hidden, key_cache, value_cache\n",
    "\n",
    "\n",
    "    def update_cache(self, key_cache, value_cache, hidden, key_cache_i, value_cache_i, hidden_i, nheads):\n",
    "        hidden_i = hidden_i.unsqueeze(0)\n",
    "        hidden = torch.cat((hidden, hidden_i), dim=0)\n",
    "        if nheads == 1:\n",
    "                key_cache_i = key_cache_i.unsqueeze(1).unsqueeze(1)\n",
    "                value_cache_i = value_cache_i.unsqueeze(1).unsqueeze(1)\n",
    "                key_cache = torch.cat((key_cache, key_cache_i), dim=2)\n",
    "                value_cache = torch.cat((value_cache, value_cache_i), dim=2)\n",
    "        else:\n",
    "            key_cache_i = key_cache_i.unsqueeze(1)\n",
    "            value_cache_i = value_cache_i.unsqueeze(1)\n",
    "            key_cache = torch.cat((key_cache, key_cache_i), dim=1)\n",
    "            value_cache = torch.cat((value_cache, value_cache_i), dim=1)\n",
    "            \n",
    "        return key_cache, value_cache, hidden\n",
    "    \n",
    "    \n",
    "    def attention_layer(self, query, key_cache, value_cache, nheads):\n",
    "        if nheads == 1:\n",
    "                query = query.unsqueeze(1)\n",
    "                \n",
    "                # Ensure all tensors are on the same device\n",
    "                if query.device != key_cache.device:\n",
    "                    key_cache = key_cache.to(query.device)\n",
    "                if query.device != value_cache.device:\n",
    "                    value_cache = value_cache.to(query.device)\n",
    "                    \n",
    "                try:\n",
    "                    attn_output = scaled_dot_product_attention(\n",
    "                        query, key_cache, value_cache, is_causal=False\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error in attention computation: {str(e)}\")\n",
    "                    raise\n",
    "                attn = attn_output.squeeze(1).squeeze(1)\n",
    "                del attn_output  # No longer needed after squeezing\n",
    "                query = query.squeeze(1).squeeze(1)\n",
    "        else:\n",
    "            attn_output, _ = self.multihead_attn(\n",
    "                query, key_cache, value_cache, is_causal=False\n",
    "            )\n",
    "            attn = attn_output.squeeze(1)\n",
    "            del attn_output  # No longer needed after squeezing\n",
    "            query = query.squeeze(1)\n",
    "            \n",
    "        return attn, query\n",
    "    \n",
    "    def intermediate_layers(self, i, emb, query, attn, hidden):\n",
    "        intermediate_input = torch.cat((emb[i], query, attn, hidden[-1]), -1)\n",
    "        del query, attn  \n",
    "        intermediate = self.drop(\n",
    "            self.tanh(self.int_norm(self.intermediate_h(intermediate_input)))\n",
    "        )\n",
    "        del intermediate_input  \n",
    "        final_output = self.drop(self.tanh(self.f_norm(self.final_h(intermediate))))\n",
    "        del intermediate  \n",
    "        key_cache_i, value_cache_i, hidden_i = final_output.split(self.nhid, dim=-1)\n",
    "        del final_output\n",
    "        return key_cache_i, value_cache_i, hidden_i\n",
    "    \n",
    "    def get_query(self, emb, hidden):\n",
    "\n",
    "        combined = torch.cat((emb, hidden[-1]), -1)\n",
    "        query = self.drop(self.tanh(self.q_norm(self.q(combined))))\n",
    "        del combined  # No longer needed after creating query\n",
    "        query = query.unsqueeze(1)\n",
    "        return query\n",
    "    \n",
    "    def forward(self, observation, initial_cache, nheads):\n",
    "        seq_len = observation.size(0)\n",
    "        print('ok')\n",
    "        hidden, key_cache, value_cache = initial_cache\n",
    "        print('hidden.shape', hidden.shape)\n",
    "        print('key_cache.shape', key_cache.shape)\n",
    "        print('value_cache.shape', value_cache.shape)\n",
    "        # 1. Encode observations\n",
    "        emb = self.drop(self.encoder(observation))\n",
    "        del observation  # No longer needed after encoding\n",
    "        \n",
    "        for i in range(seq_len):\n",
    "            # 2. Concatenate with previous hidden state\n",
    "            \n",
    "            \n",
    "            \n",
    "            query = self.get_query(emb[i], hidden)\n",
    "            \n",
    "            attn, query = self.attention_layer(query, key_cache, value_cache, nheads)\n",
    "\n",
    "            key_cache_i, value_cache_i, hidden_i = self.intermediate_layers(i, emb, query, attn, hidden)\n",
    "            \n",
    "            key_cache, value_cache, hidden = self.update_cache(key_cache, value_cache, hidden, key_cache_i, value_cache_i, hidden_i, nheads)\n",
    "\n",
    "            del key_cache_i, value_cache_i, hidden_i  # No longer needed after concatenation\n",
    "            print('key_cache.shape', key_cache.shape)\n",
    "            print('value_cache.shape', value_cache.shape)\n",
    "            print('hidden.shape', hidden.shape)\n",
    "        cache = (hidden, key_cache, value_cache)\n",
    "        decoded = self.decoder(hidden[1:])\n",
    "\n",
    "        return decoded, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CBR_RNN(50001, ninp=128, nhid=128, nheads=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Turn on training mode which enables dropout\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    \n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, 35)):\n",
    "        # Get batch\n",
    "        data, targets = get_batch(train_data, i, 35)\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        cache = model.init_cache(data, 1)\n",
    "        \n",
    "            # Forward pass on chunk\n",
    "        output,_ = model(data, cache, 1)\n",
    "        \n",
    "        \n",
    "        # Reshape outputs and targets\n",
    "        output_flat = output.reshape(-1, output.size(-1))\n",
    "        targets_flat = targets.reshape(-1)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(output_flat, targets_flat)\n",
    "        del output, output_flat, targets_flat\n",
    "      \n",
    "\n",
    "       \n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "\n",
    "        optimizer.step()   \n",
    "\n",
    "        total_loss += loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "hidden.shape torch.Size([1, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 1, 128])\n",
      "value_cache.shape torch.Size([128, 1, 1, 128])\n",
      "key_cache.shape torch.Size([128, 1, 2, 128])\n",
      "value_cache.shape torch.Size([128, 1, 2, 128])\n",
      "hidden.shape torch.Size([2, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 3, 128])\n",
      "value_cache.shape torch.Size([128, 1, 3, 128])\n",
      "hidden.shape torch.Size([3, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 4, 128])\n",
      "value_cache.shape torch.Size([128, 1, 4, 128])\n",
      "hidden.shape torch.Size([4, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 5, 128])\n",
      "value_cache.shape torch.Size([128, 1, 5, 128])\n",
      "hidden.shape torch.Size([5, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 6, 128])\n",
      "value_cache.shape torch.Size([128, 1, 6, 128])\n",
      "hidden.shape torch.Size([6, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 7, 128])\n",
      "value_cache.shape torch.Size([128, 1, 7, 128])\n",
      "hidden.shape torch.Size([7, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 8, 128])\n",
      "value_cache.shape torch.Size([128, 1, 8, 128])\n",
      "hidden.shape torch.Size([8, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 9, 128])\n",
      "value_cache.shape torch.Size([128, 1, 9, 128])\n",
      "hidden.shape torch.Size([9, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 10, 128])\n",
      "value_cache.shape torch.Size([128, 1, 10, 128])\n",
      "hidden.shape torch.Size([10, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 11, 128])\n",
      "value_cache.shape torch.Size([128, 1, 11, 128])\n",
      "hidden.shape torch.Size([11, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 12, 128])\n",
      "value_cache.shape torch.Size([128, 1, 12, 128])\n",
      "hidden.shape torch.Size([12, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 13, 128])\n",
      "value_cache.shape torch.Size([128, 1, 13, 128])\n",
      "hidden.shape torch.Size([13, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 14, 128])\n",
      "value_cache.shape torch.Size([128, 1, 14, 128])\n",
      "hidden.shape torch.Size([14, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 15, 128])\n",
      "value_cache.shape torch.Size([128, 1, 15, 128])\n",
      "hidden.shape torch.Size([15, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 16, 128])\n",
      "value_cache.shape torch.Size([128, 1, 16, 128])\n",
      "hidden.shape torch.Size([16, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 17, 128])\n",
      "value_cache.shape torch.Size([128, 1, 17, 128])\n",
      "hidden.shape torch.Size([17, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 18, 128])\n",
      "value_cache.shape torch.Size([128, 1, 18, 128])\n",
      "hidden.shape torch.Size([18, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 19, 128])\n",
      "value_cache.shape torch.Size([128, 1, 19, 128])\n",
      "hidden.shape torch.Size([19, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 20, 128])\n",
      "value_cache.shape torch.Size([128, 1, 20, 128])\n",
      "hidden.shape torch.Size([20, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 21, 128])\n",
      "value_cache.shape torch.Size([128, 1, 21, 128])\n",
      "hidden.shape torch.Size([21, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 22, 128])\n",
      "value_cache.shape torch.Size([128, 1, 22, 128])\n",
      "hidden.shape torch.Size([22, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 23, 128])\n",
      "value_cache.shape torch.Size([128, 1, 23, 128])\n",
      "hidden.shape torch.Size([23, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 24, 128])\n",
      "value_cache.shape torch.Size([128, 1, 24, 128])\n",
      "hidden.shape torch.Size([24, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 25, 128])\n",
      "value_cache.shape torch.Size([128, 1, 25, 128])\n",
      "hidden.shape torch.Size([25, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 26, 128])\n",
      "value_cache.shape torch.Size([128, 1, 26, 128])\n",
      "hidden.shape torch.Size([26, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 27, 128])\n",
      "value_cache.shape torch.Size([128, 1, 27, 128])\n",
      "hidden.shape torch.Size([27, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 28, 128])\n",
      "value_cache.shape torch.Size([128, 1, 28, 128])\n",
      "hidden.shape torch.Size([28, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 29, 128])\n",
      "value_cache.shape torch.Size([128, 1, 29, 128])\n",
      "hidden.shape torch.Size([29, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 30, 128])\n",
      "value_cache.shape torch.Size([128, 1, 30, 128])\n",
      "hidden.shape torch.Size([30, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 31, 128])\n",
      "value_cache.shape torch.Size([128, 1, 31, 128])\n",
      "hidden.shape torch.Size([31, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 32, 128])\n",
      "value_cache.shape torch.Size([128, 1, 32, 128])\n",
      "hidden.shape torch.Size([32, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 33, 128])\n",
      "value_cache.shape torch.Size([128, 1, 33, 128])\n",
      "hidden.shape torch.Size([33, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 34, 128])\n",
      "value_cache.shape torch.Size([128, 1, 34, 128])\n",
      "hidden.shape torch.Size([34, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 35, 128])\n",
      "value_cache.shape torch.Size([128, 1, 35, 128])\n",
      "hidden.shape torch.Size([35, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 36, 128])\n",
      "value_cache.shape torch.Size([128, 1, 36, 128])\n",
      "hidden.shape torch.Size([36, 128, 128])\n",
      "ok\n",
      "hidden.shape torch.Size([1, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 1, 128])\n",
      "value_cache.shape torch.Size([128, 1, 1, 128])\n",
      "key_cache.shape torch.Size([128, 1, 2, 128])\n",
      "value_cache.shape torch.Size([128, 1, 2, 128])\n",
      "hidden.shape torch.Size([2, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 3, 128])\n",
      "value_cache.shape torch.Size([128, 1, 3, 128])\n",
      "hidden.shape torch.Size([3, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 4, 128])\n",
      "value_cache.shape torch.Size([128, 1, 4, 128])\n",
      "hidden.shape torch.Size([4, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 5, 128])\n",
      "value_cache.shape torch.Size([128, 1, 5, 128])\n",
      "hidden.shape torch.Size([5, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 6, 128])\n",
      "value_cache.shape torch.Size([128, 1, 6, 128])\n",
      "hidden.shape torch.Size([6, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 7, 128])\n",
      "value_cache.shape torch.Size([128, 1, 7, 128])\n",
      "hidden.shape torch.Size([7, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 8, 128])\n",
      "value_cache.shape torch.Size([128, 1, 8, 128])\n",
      "hidden.shape torch.Size([8, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 9, 128])\n",
      "value_cache.shape torch.Size([128, 1, 9, 128])\n",
      "hidden.shape torch.Size([9, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 10, 128])\n",
      "value_cache.shape torch.Size([128, 1, 10, 128])\n",
      "hidden.shape torch.Size([10, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 11, 128])\n",
      "value_cache.shape torch.Size([128, 1, 11, 128])\n",
      "hidden.shape torch.Size([11, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 12, 128])\n",
      "value_cache.shape torch.Size([128, 1, 12, 128])\n",
      "hidden.shape torch.Size([12, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 13, 128])\n",
      "value_cache.shape torch.Size([128, 1, 13, 128])\n",
      "hidden.shape torch.Size([13, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 14, 128])\n",
      "value_cache.shape torch.Size([128, 1, 14, 128])\n",
      "hidden.shape torch.Size([14, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 15, 128])\n",
      "value_cache.shape torch.Size([128, 1, 15, 128])\n",
      "hidden.shape torch.Size([15, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 16, 128])\n",
      "value_cache.shape torch.Size([128, 1, 16, 128])\n",
      "hidden.shape torch.Size([16, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 17, 128])\n",
      "value_cache.shape torch.Size([128, 1, 17, 128])\n",
      "hidden.shape torch.Size([17, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 18, 128])\n",
      "value_cache.shape torch.Size([128, 1, 18, 128])\n",
      "hidden.shape torch.Size([18, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 19, 128])\n",
      "value_cache.shape torch.Size([128, 1, 19, 128])\n",
      "hidden.shape torch.Size([19, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 20, 128])\n",
      "value_cache.shape torch.Size([128, 1, 20, 128])\n",
      "hidden.shape torch.Size([20, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 21, 128])\n",
      "value_cache.shape torch.Size([128, 1, 21, 128])\n",
      "hidden.shape torch.Size([21, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 22, 128])\n",
      "value_cache.shape torch.Size([128, 1, 22, 128])\n",
      "hidden.shape torch.Size([22, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 23, 128])\n",
      "value_cache.shape torch.Size([128, 1, 23, 128])\n",
      "hidden.shape torch.Size([23, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 24, 128])\n",
      "value_cache.shape torch.Size([128, 1, 24, 128])\n",
      "hidden.shape torch.Size([24, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 25, 128])\n",
      "value_cache.shape torch.Size([128, 1, 25, 128])\n",
      "hidden.shape torch.Size([25, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 26, 128])\n",
      "value_cache.shape torch.Size([128, 1, 26, 128])\n",
      "hidden.shape torch.Size([26, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 27, 128])\n",
      "value_cache.shape torch.Size([128, 1, 27, 128])\n",
      "hidden.shape torch.Size([27, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 28, 128])\n",
      "value_cache.shape torch.Size([128, 1, 28, 128])\n",
      "hidden.shape torch.Size([28, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 29, 128])\n",
      "value_cache.shape torch.Size([128, 1, 29, 128])\n",
      "hidden.shape torch.Size([29, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 30, 128])\n",
      "value_cache.shape torch.Size([128, 1, 30, 128])\n",
      "hidden.shape torch.Size([30, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 31, 128])\n",
      "value_cache.shape torch.Size([128, 1, 31, 128])\n",
      "hidden.shape torch.Size([31, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 32, 128])\n",
      "value_cache.shape torch.Size([128, 1, 32, 128])\n",
      "hidden.shape torch.Size([32, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 33, 128])\n",
      "value_cache.shape torch.Size([128, 1, 33, 128])\n",
      "hidden.shape torch.Size([33, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 34, 128])\n",
      "value_cache.shape torch.Size([128, 1, 34, 128])\n",
      "hidden.shape torch.Size([34, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 35, 128])\n",
      "value_cache.shape torch.Size([128, 1, 35, 128])\n",
      "hidden.shape torch.Size([35, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 36, 128])\n",
      "value_cache.shape torch.Size([128, 1, 36, 128])\n",
      "hidden.shape torch.Size([36, 128, 128])\n",
      "ok\n",
      "hidden.shape torch.Size([1, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 1, 128])\n",
      "value_cache.shape torch.Size([128, 1, 1, 128])\n",
      "key_cache.shape torch.Size([128, 1, 2, 128])\n",
      "value_cache.shape torch.Size([128, 1, 2, 128])\n",
      "hidden.shape torch.Size([2, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 3, 128])\n",
      "value_cache.shape torch.Size([128, 1, 3, 128])\n",
      "hidden.shape torch.Size([3, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 4, 128])\n",
      "value_cache.shape torch.Size([128, 1, 4, 128])\n",
      "hidden.shape torch.Size([4, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 5, 128])\n",
      "value_cache.shape torch.Size([128, 1, 5, 128])\n",
      "hidden.shape torch.Size([5, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 6, 128])\n",
      "value_cache.shape torch.Size([128, 1, 6, 128])\n",
      "hidden.shape torch.Size([6, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 7, 128])\n",
      "value_cache.shape torch.Size([128, 1, 7, 128])\n",
      "hidden.shape torch.Size([7, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 8, 128])\n",
      "value_cache.shape torch.Size([128, 1, 8, 128])\n",
      "hidden.shape torch.Size([8, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 9, 128])\n",
      "value_cache.shape torch.Size([128, 1, 9, 128])\n",
      "hidden.shape torch.Size([9, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 10, 128])\n",
      "value_cache.shape torch.Size([128, 1, 10, 128])\n",
      "hidden.shape torch.Size([10, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 11, 128])\n",
      "value_cache.shape torch.Size([128, 1, 11, 128])\n",
      "hidden.shape torch.Size([11, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 12, 128])\n",
      "value_cache.shape torch.Size([128, 1, 12, 128])\n",
      "hidden.shape torch.Size([12, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 13, 128])\n",
      "value_cache.shape torch.Size([128, 1, 13, 128])\n",
      "hidden.shape torch.Size([13, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 14, 128])\n",
      "value_cache.shape torch.Size([128, 1, 14, 128])\n",
      "hidden.shape torch.Size([14, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 15, 128])\n",
      "value_cache.shape torch.Size([128, 1, 15, 128])\n",
      "hidden.shape torch.Size([15, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 16, 128])\n",
      "value_cache.shape torch.Size([128, 1, 16, 128])\n",
      "hidden.shape torch.Size([16, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 17, 128])\n",
      "value_cache.shape torch.Size([128, 1, 17, 128])\n",
      "hidden.shape torch.Size([17, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 18, 128])\n",
      "value_cache.shape torch.Size([128, 1, 18, 128])\n",
      "hidden.shape torch.Size([18, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 19, 128])\n",
      "value_cache.shape torch.Size([128, 1, 19, 128])\n",
      "hidden.shape torch.Size([19, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 20, 128])\n",
      "value_cache.shape torch.Size([128, 1, 20, 128])\n",
      "hidden.shape torch.Size([20, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 21, 128])\n",
      "value_cache.shape torch.Size([128, 1, 21, 128])\n",
      "hidden.shape torch.Size([21, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 22, 128])\n",
      "value_cache.shape torch.Size([128, 1, 22, 128])\n",
      "hidden.shape torch.Size([22, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 23, 128])\n",
      "value_cache.shape torch.Size([128, 1, 23, 128])\n",
      "hidden.shape torch.Size([23, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 24, 128])\n",
      "value_cache.shape torch.Size([128, 1, 24, 128])\n",
      "hidden.shape torch.Size([24, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 25, 128])\n",
      "value_cache.shape torch.Size([128, 1, 25, 128])\n",
      "hidden.shape torch.Size([25, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 26, 128])\n",
      "value_cache.shape torch.Size([128, 1, 26, 128])\n",
      "hidden.shape torch.Size([26, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 27, 128])\n",
      "value_cache.shape torch.Size([128, 1, 27, 128])\n",
      "hidden.shape torch.Size([27, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 28, 128])\n",
      "value_cache.shape torch.Size([128, 1, 28, 128])\n",
      "hidden.shape torch.Size([28, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 29, 128])\n",
      "value_cache.shape torch.Size([128, 1, 29, 128])\n",
      "hidden.shape torch.Size([29, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 30, 128])\n",
      "value_cache.shape torch.Size([128, 1, 30, 128])\n",
      "hidden.shape torch.Size([30, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 31, 128])\n",
      "value_cache.shape torch.Size([128, 1, 31, 128])\n",
      "hidden.shape torch.Size([31, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 32, 128])\n",
      "value_cache.shape torch.Size([128, 1, 32, 128])\n",
      "hidden.shape torch.Size([32, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 33, 128])\n",
      "value_cache.shape torch.Size([128, 1, 33, 128])\n",
      "hidden.shape torch.Size([33, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 34, 128])\n",
      "value_cache.shape torch.Size([128, 1, 34, 128])\n",
      "hidden.shape torch.Size([34, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 35, 128])\n",
      "value_cache.shape torch.Size([128, 1, 35, 128])\n",
      "hidden.shape torch.Size([35, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 36, 128])\n",
      "value_cache.shape torch.Size([128, 1, 36, 128])\n",
      "hidden.shape torch.Size([36, 128, 128])\n",
      "ok\n",
      "hidden.shape torch.Size([1, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 1, 128])\n",
      "value_cache.shape torch.Size([128, 1, 1, 128])\n",
      "key_cache.shape torch.Size([128, 1, 2, 128])\n",
      "value_cache.shape torch.Size([128, 1, 2, 128])\n",
      "hidden.shape torch.Size([2, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 3, 128])\n",
      "value_cache.shape torch.Size([128, 1, 3, 128])\n",
      "hidden.shape torch.Size([3, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 4, 128])\n",
      "value_cache.shape torch.Size([128, 1, 4, 128])\n",
      "hidden.shape torch.Size([4, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 5, 128])\n",
      "value_cache.shape torch.Size([128, 1, 5, 128])\n",
      "hidden.shape torch.Size([5, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 6, 128])\n",
      "value_cache.shape torch.Size([128, 1, 6, 128])\n",
      "hidden.shape torch.Size([6, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 7, 128])\n",
      "value_cache.shape torch.Size([128, 1, 7, 128])\n",
      "hidden.shape torch.Size([7, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 8, 128])\n",
      "value_cache.shape torch.Size([128, 1, 8, 128])\n",
      "hidden.shape torch.Size([8, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 9, 128])\n",
      "value_cache.shape torch.Size([128, 1, 9, 128])\n",
      "hidden.shape torch.Size([9, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 10, 128])\n",
      "value_cache.shape torch.Size([128, 1, 10, 128])\n",
      "hidden.shape torch.Size([10, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 11, 128])\n",
      "value_cache.shape torch.Size([128, 1, 11, 128])\n",
      "hidden.shape torch.Size([11, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 12, 128])\n",
      "value_cache.shape torch.Size([128, 1, 12, 128])\n",
      "hidden.shape torch.Size([12, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 13, 128])\n",
      "value_cache.shape torch.Size([128, 1, 13, 128])\n",
      "hidden.shape torch.Size([13, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 14, 128])\n",
      "value_cache.shape torch.Size([128, 1, 14, 128])\n",
      "hidden.shape torch.Size([14, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 15, 128])\n",
      "value_cache.shape torch.Size([128, 1, 15, 128])\n",
      "hidden.shape torch.Size([15, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 16, 128])\n",
      "value_cache.shape torch.Size([128, 1, 16, 128])\n",
      "hidden.shape torch.Size([16, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 17, 128])\n",
      "value_cache.shape torch.Size([128, 1, 17, 128])\n",
      "hidden.shape torch.Size([17, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 18, 128])\n",
      "value_cache.shape torch.Size([128, 1, 18, 128])\n",
      "hidden.shape torch.Size([18, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 19, 128])\n",
      "value_cache.shape torch.Size([128, 1, 19, 128])\n",
      "hidden.shape torch.Size([19, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 20, 128])\n",
      "value_cache.shape torch.Size([128, 1, 20, 128])\n",
      "hidden.shape torch.Size([20, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 21, 128])\n",
      "value_cache.shape torch.Size([128, 1, 21, 128])\n",
      "hidden.shape torch.Size([21, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 22, 128])\n",
      "value_cache.shape torch.Size([128, 1, 22, 128])\n",
      "hidden.shape torch.Size([22, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 23, 128])\n",
      "value_cache.shape torch.Size([128, 1, 23, 128])\n",
      "hidden.shape torch.Size([23, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 24, 128])\n",
      "value_cache.shape torch.Size([128, 1, 24, 128])\n",
      "hidden.shape torch.Size([24, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 25, 128])\n",
      "value_cache.shape torch.Size([128, 1, 25, 128])\n",
      "hidden.shape torch.Size([25, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 26, 128])\n",
      "value_cache.shape torch.Size([128, 1, 26, 128])\n",
      "hidden.shape torch.Size([26, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 27, 128])\n",
      "value_cache.shape torch.Size([128, 1, 27, 128])\n",
      "hidden.shape torch.Size([27, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 28, 128])\n",
      "value_cache.shape torch.Size([128, 1, 28, 128])\n",
      "hidden.shape torch.Size([28, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 29, 128])\n",
      "value_cache.shape torch.Size([128, 1, 29, 128])\n",
      "hidden.shape torch.Size([29, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 30, 128])\n",
      "value_cache.shape torch.Size([128, 1, 30, 128])\n",
      "hidden.shape torch.Size([30, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 31, 128])\n",
      "value_cache.shape torch.Size([128, 1, 31, 128])\n",
      "hidden.shape torch.Size([31, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 32, 128])\n",
      "value_cache.shape torch.Size([128, 1, 32, 128])\n",
      "hidden.shape torch.Size([32, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 33, 128])\n",
      "value_cache.shape torch.Size([128, 1, 33, 128])\n",
      "hidden.shape torch.Size([33, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 34, 128])\n",
      "value_cache.shape torch.Size([128, 1, 34, 128])\n",
      "hidden.shape torch.Size([34, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 35, 128])\n",
      "value_cache.shape torch.Size([128, 1, 35, 128])\n",
      "hidden.shape torch.Size([35, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 36, 128])\n",
      "value_cache.shape torch.Size([128, 1, 36, 128])\n",
      "hidden.shape torch.Size([36, 128, 128])\n",
      "ok\n",
      "hidden.shape torch.Size([1, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 1, 128])\n",
      "value_cache.shape torch.Size([128, 1, 1, 128])\n",
      "key_cache.shape torch.Size([128, 1, 2, 128])\n",
      "value_cache.shape torch.Size([128, 1, 2, 128])\n",
      "hidden.shape torch.Size([2, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 3, 128])\n",
      "value_cache.shape torch.Size([128, 1, 3, 128])\n",
      "hidden.shape torch.Size([3, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 4, 128])\n",
      "value_cache.shape torch.Size([128, 1, 4, 128])\n",
      "hidden.shape torch.Size([4, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 5, 128])\n",
      "value_cache.shape torch.Size([128, 1, 5, 128])\n",
      "hidden.shape torch.Size([5, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 6, 128])\n",
      "value_cache.shape torch.Size([128, 1, 6, 128])\n",
      "hidden.shape torch.Size([6, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 7, 128])\n",
      "value_cache.shape torch.Size([128, 1, 7, 128])\n",
      "hidden.shape torch.Size([7, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 8, 128])\n",
      "value_cache.shape torch.Size([128, 1, 8, 128])\n",
      "hidden.shape torch.Size([8, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 9, 128])\n",
      "value_cache.shape torch.Size([128, 1, 9, 128])\n",
      "hidden.shape torch.Size([9, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 10, 128])\n",
      "value_cache.shape torch.Size([128, 1, 10, 128])\n",
      "hidden.shape torch.Size([10, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 11, 128])\n",
      "value_cache.shape torch.Size([128, 1, 11, 128])\n",
      "hidden.shape torch.Size([11, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 12, 128])\n",
      "value_cache.shape torch.Size([128, 1, 12, 128])\n",
      "hidden.shape torch.Size([12, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 13, 128])\n",
      "value_cache.shape torch.Size([128, 1, 13, 128])\n",
      "hidden.shape torch.Size([13, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 14, 128])\n",
      "value_cache.shape torch.Size([128, 1, 14, 128])\n",
      "hidden.shape torch.Size([14, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 15, 128])\n",
      "value_cache.shape torch.Size([128, 1, 15, 128])\n",
      "hidden.shape torch.Size([15, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 16, 128])\n",
      "value_cache.shape torch.Size([128, 1, 16, 128])\n",
      "hidden.shape torch.Size([16, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 17, 128])\n",
      "value_cache.shape torch.Size([128, 1, 17, 128])\n",
      "hidden.shape torch.Size([17, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 18, 128])\n",
      "value_cache.shape torch.Size([128, 1, 18, 128])\n",
      "hidden.shape torch.Size([18, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 19, 128])\n",
      "value_cache.shape torch.Size([128, 1, 19, 128])\n",
      "hidden.shape torch.Size([19, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 20, 128])\n",
      "value_cache.shape torch.Size([128, 1, 20, 128])\n",
      "hidden.shape torch.Size([20, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 21, 128])\n",
      "value_cache.shape torch.Size([128, 1, 21, 128])\n",
      "hidden.shape torch.Size([21, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 22, 128])\n",
      "value_cache.shape torch.Size([128, 1, 22, 128])\n",
      "hidden.shape torch.Size([22, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 23, 128])\n",
      "value_cache.shape torch.Size([128, 1, 23, 128])\n",
      "hidden.shape torch.Size([23, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 24, 128])\n",
      "value_cache.shape torch.Size([128, 1, 24, 128])\n",
      "hidden.shape torch.Size([24, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 25, 128])\n",
      "value_cache.shape torch.Size([128, 1, 25, 128])\n",
      "hidden.shape torch.Size([25, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 26, 128])\n",
      "value_cache.shape torch.Size([128, 1, 26, 128])\n",
      "hidden.shape torch.Size([26, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 27, 128])\n",
      "value_cache.shape torch.Size([128, 1, 27, 128])\n",
      "hidden.shape torch.Size([27, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 28, 128])\n",
      "value_cache.shape torch.Size([128, 1, 28, 128])\n",
      "hidden.shape torch.Size([28, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 29, 128])\n",
      "value_cache.shape torch.Size([128, 1, 29, 128])\n",
      "hidden.shape torch.Size([29, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 30, 128])\n",
      "value_cache.shape torch.Size([128, 1, 30, 128])\n",
      "hidden.shape torch.Size([30, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 31, 128])\n",
      "value_cache.shape torch.Size([128, 1, 31, 128])\n",
      "hidden.shape torch.Size([31, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 32, 128])\n",
      "value_cache.shape torch.Size([128, 1, 32, 128])\n",
      "hidden.shape torch.Size([32, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 33, 128])\n",
      "value_cache.shape torch.Size([128, 1, 33, 128])\n",
      "hidden.shape torch.Size([33, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 34, 128])\n",
      "value_cache.shape torch.Size([128, 1, 34, 128])\n",
      "hidden.shape torch.Size([34, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 35, 128])\n",
      "value_cache.shape torch.Size([128, 1, 35, 128])\n",
      "hidden.shape torch.Size([35, 128, 128])\n",
      "key_cache.shape torch.Size([128, 1, 36, 128])\n",
      "value_cache.shape torch.Size([128, 1, 36, 128])\n",
      "hidden.shape torch.Size([36, 128, 128])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[83], line 28\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[1;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output_flat, targets_flat)\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m output, output_flat, targets_flat\n\u001b[1;32m     32\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     34\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leaps3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
